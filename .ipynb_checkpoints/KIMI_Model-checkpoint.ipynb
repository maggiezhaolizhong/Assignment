{
 "cells": [
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-02T15:42:05.292247Z",
     "start_time": "2024-11-02T15:42:05.272542Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "import os\n",
    "import openai\n",
    "import datasets\n",
    "import asyncio\n",
    "import argparse\n",
    "from tqdm.asyncio import tqdm_asyncio\n",
    "\n",
    "def get_prompt_template():\n",
    "  print(\"Enter a prompt:\")\n",
    "  user_input = sys.stdin.readline().strip()\n",
    "  if not user_input:\n",
    "    user_input = \"\"\"Answer the question: \"\"\"\n",
    "  #  print(user_input)\n",
    "  return user_input\n",
    "\n",
    "# get response from AI model\n",
    "async def get_llm_response_async(prompt, prompt_template, model):\n",
    "  formatted_prompt = prompt_template + prompt\n",
    "  openai_api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "  #print(f\"openai_api_key:{openai_api_key}\")\n",
    "  client = openai.AsyncOpenAI(api_key=openai_api_key,\n",
    "                              base_url=\"https://api.moonshot.cn/v1\"\n",
    "                              )\n",
    "  \n",
    "  response = await client.chat.completions.create(\n",
    "      model=model,\n",
    "      messages=[\n",
    "          {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "          {\"role\": \"user\", \"content\": formatted_prompt}\n",
    "      ],\n",
    "      max_tokens=500,  # Adjust as needed\n",
    "      n=1, \n",
    "      stop=None,\n",
    "      temperature=0.0, #0-1\n",
    "  )\n",
    "\n",
    "  return response.choices[0].message.content.strip()\n",
    "\n",
    "def evaluate(response, target):\n",
    "  response_label = response.split()[0].strip(\"() \")  # Extract the answer label\n",
    "  target_label = target.strip(\"() \")\n",
    "  return response_label == target_label\n",
    "\n",
    "async def main(args):\n",
    "\n",
    "  dataset = datasets.load_dataset(\"lukaemon/bbh\", \"reasoning_about_colored_objects\")\n",
    "  subset = dataset[\"test\"].shuffle(seed=args.seed).select(range(args.limit))\n",
    "\n",
    "  # for item in subset:\n",
    "  #   print(item)\n",
    "  # example : {\"input\":xxxx,\"target\":(F)}\n",
    "\n",
    "  prompt_template = get_prompt_template() # user_input or \"Answer the question:\"\n",
    "\n",
    "  semaphore = asyncio.Semaphore(args.concurrency)\n",
    "\n",
    "  from pprint import pprint\n",
    "  async def process_example(example):\n",
    "    async with semaphore:\n",
    "      input_ = example[\"input\"]\n",
    "      target = example[\"target\"]\n",
    "      response = await get_llm_response_async(input_, prompt_template, args.model)\n",
    "      is_correct = evaluate(response, target)\n",
    "      result = {\n",
    "        'question': input_,\n",
    "        'ground_truth': target,\n",
    "        'model_response': response,\n",
    "        'is_correct': is_correct\n",
    "      }\n",
    "      # if not is_correct:\n",
    "      #   print(result)\n",
    "      return result\n",
    "\n",
    "  tasks = [process_example(example) for example in subset] # result list\n",
    "\n",
    "  evaluation_results = await tqdm_asyncio.gather(*tasks, desc=\"Processing examples\")\n",
    " \n",
    "  # Calculate and print the metrics\n",
    "  accuracy = 0\n",
    "  # TODO: calculate accuracy\n",
    "  example_pass = sum(1 for res in evaluation_results if res[\"is_correct\"])\n",
    "  accuracy = example_pass / len(tasks) * 100\n",
    "  print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "  # TODO: implement any other metric that you think might be usefull\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  args = argparse.ArgumentParser()\n",
    "  args.add_argument(\"--limit\", type=int, default=100) # limit 100 examples\n",
    "  #args.add_argument(\"--model\", type=str, default=\"gpt-3.5-turbo\")\n",
    "  # models \"moonshot-v1-8k\",\"moonshot-v1-32k\",\"moonshot-v1-128k\"\n",
    "  args.add_argument(\"--model\", type=str, default=\"moonshot-v1-8k\")\n",
    "  args.add_argument(\"--seed\", type=int, default=42)\n",
    "  args.add_argument(\"--concurrency\", type=int, default=5)\n",
    "  args = args.parse_args()\n",
    "\n",
    "  asyncio.run(main(args))\n"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--limit LIMIT] [--model MODEL]\n",
      "                             [--seed SEED] [--concurrency CONCURRENCY]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /Users/maza/Library/Jupyter/runtime/kernel-7e123d17-3a66-4ea1-a117-feaef8aaf590.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001B[0;31mSystemExit\u001B[0m\u001B[0;31m:\u001B[0m 2\n"
     ]
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
