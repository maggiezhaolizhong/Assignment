{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The following piece of code supports the AI model KIMI, which is based on OpenAI. I used this model in the script because I couldn't create an OpenAI API key with a Chinese phone number.\n",
    "\n",
    "Create an api key in \"https://platform.moonshot.cn/console/api-keys\", then create Environment variable.\n",
    "\n",
    "Prompts and accuracy:\n",
    "1. please carefully read the text and the following question, pick the correct one from the given options:   87.00\n",
    "2. Choose the right option based on the information provided:  85.00\n",
    "3. Find the correct option among the following choices:   85.00\n",
    "4. Please select the correct option based on the information provided：  84.00\n",
    "5. Your task is to choose the correct option based on the following description:    84.00\n",
    "6. Select the most appropriate answer from the options:  84.00\n",
    "7. Please select the correct answer:   84.00\n",
    "8. Based on the details, what is the correct answer?   82.00\n",
    "9. Answer the question:   81.00\n",
    "10. Please answer the following question:  73.00\n",
    "11. 根据提供的信息选择正确的选项：  83.00\n",
    "12. 根据给出的细节，找出正确的答案： 80.00\n",
    "13. 请回答问题：   72.00"
   ],
   "id": "d8dee3bbb0375d3b"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T05:42:26.337772Z",
     "start_time": "2024-11-04T05:41:08.181481Z"
    }
   },
   "source": [
    "import sys\n",
    "import os\n",
    "import openai\n",
    "import datasets\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "import argparse\n",
    "from tqdm.asyncio import tqdm_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "def get_prompt_template():\n",
    "  print(\"Enter a prompt:\")\n",
    "  user_input = input().strip()\n",
    "  if not user_input:\n",
    "    user_input = \"\"\"Answer the question: \"\"\"\n",
    "  print(user_input)\n",
    "  return user_input\n",
    "\n",
    "# get response from AI model\n",
    "async def get_llm_response_async(prompt, prompt_template, model):\n",
    "  formatted_prompt = prompt_template + prompt\n",
    "  openai_api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "  #print(f\"openai_api_key:{openai_api_key}\")\n",
    "  client = openai.AsyncOpenAI(api_key=openai_api_key,\n",
    "                              base_url=\"https://api.moonshot.cn/v1\"\n",
    "                              )\n",
    "  \n",
    "  response = await client.chat.completions.create(\n",
    "      model=model,\n",
    "      messages=[\n",
    "          {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "          {\"role\": \"user\", \"content\": formatted_prompt}\n",
    "      ],\n",
    "      max_tokens=500,  # Adjust as needed\n",
    "      n=1, \n",
    "      stop=None,\n",
    "      temperature=0.0, #0-1\n",
    "  )\n",
    "\n",
    "  return response.choices[0].message.content.strip()\n",
    "\n",
    "def evaluate(response, target):\n",
    "  response_label = response.split()[0].strip(\"() \")  # Extract the answer label\n",
    "  target_label = target.strip(\"() \")\n",
    "  return response_label == target_label\n",
    "\n",
    "async def main(args):\n",
    "\n",
    "  dataset = datasets.load_dataset(\"lukaemon/bbh\", \"reasoning_about_colored_objects\")\n",
    "  subset = dataset[\"test\"].shuffle(seed=args.seed).select(range(args.limit))\n",
    "  # for item in subset:\n",
    "  #   print(item)\n",
    "  # example : {\"input\":xxxx,\"target\":(F)}\n",
    "\n",
    "  prompt_template = get_prompt_template() # user_input or \"Answer the question:\"\n",
    "\n",
    "  semaphore = asyncio.Semaphore(args.concurrency)\n",
    "\n",
    "  from pprint import pprint\n",
    "  async def process_example(example):\n",
    "    async with semaphore:\n",
    "      input_ = example[\"input\"]\n",
    "      target = example[\"target\"]\n",
    "      response = await get_llm_response_async(input_, prompt_template, args.model)\n",
    "      is_correct = evaluate(response, target)\n",
    "      result = {\n",
    "        'question': input_,\n",
    "        'ground_truth': target,\n",
    "        'model_response': response,\n",
    "        'is_correct': is_correct\n",
    "      }\n",
    "      # if not is_correct:\n",
    "      #   print(result)\n",
    "      return result\n",
    "\n",
    "  tasks = [process_example(example) for example in subset] # result list\n",
    "\n",
    "  evaluation_results = await tqdm_asyncio.gather(*tasks, desc=\"Processing examples\")\n",
    " \n",
    "  # Calculate and print the metrics\n",
    "  accuracy = 0\n",
    "  # TODO: calculate accuracy\n",
    "  example_pass = sum(1 for res in evaluation_results if res[\"is_correct\"])\n",
    "  accuracy = example_pass / len(tasks) * 100\n",
    "  print(f\"Accuracy: {accuracy:.2f}\")\n",
    "  \n",
    "\n",
    "  # TODO: implement any other metric that you think might be usefull\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  args = argparse.ArgumentParser()\n",
    "  args.add_argument(\"--limit\", type=int, default=100) # limit 100 examples\n",
    "  #args.add_argument(\"--model\", type=str, default=\"gpt-3.5-turbo\")\n",
    "  #models \"moonshot-v1-8k\",\"moonshot-v1-32k\",\"moonshot-v1-128k\"\n",
    "  args.add_argument(\"--model\", type=str, default=\"moonshot-v1-8k\")\n",
    "  args.add_argument(\"--seed\", type=int, default=42)\n",
    "  args.add_argument(\"--concurrency\", type=int, default=5)\n",
    "  \n",
    "  args = args.parse_known_args()[0]\n",
    "  \n",
    "  asyncio.run(main(args))\n",
    "  "
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a prompt:\n",
      "请回答问题：\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing examples: 100%|██████████| 100/100 [01:04<00:00,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 72.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The following piece of code supports openai model, I haven't actually run it myself because I wasn't able to create a openai api key using a Chinese phone number. I believe it will work well with a valid openai api key. ",
   "id": "b459a64fa1bc39f9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import sys\n",
    "import os\n",
    "import openai\n",
    "import datasets\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "import argparse\n",
    "from tqdm.asyncio import tqdm_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "def get_prompt_template():\n",
    "  print(\"Enter a prompt:\")\n",
    "  user_input = input().strip()\n",
    "  if not user_input:\n",
    "    user_input = \"\"\"Answer the question: \"\"\"\n",
    "  print(user_input)\n",
    "  return user_input\n",
    "\n",
    "# get response from AI model\n",
    "async def get_llm_response_async(prompt, prompt_template, model):\n",
    "  formatted_prompt = prompt_template + prompt\n",
    "  openai_api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "  client = openai.AsyncOpenAI(api_key=openai_api_key)\n",
    "  \n",
    "  response = await client.chat.completions.create(\n",
    "      model=model,\n",
    "      messages=[\n",
    "          {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "          {\"role\": \"user\", \"content\": formatted_prompt}\n",
    "      ],\n",
    "      max_tokens=500,  # Adjust as needed\n",
    "      n=1, \n",
    "      stop=None,\n",
    "      temperature=0.0, #0-1\n",
    "  )\n",
    "\n",
    "  return response.choices[0].message.content.strip()\n",
    "\n",
    "def evaluate(response, target):\n",
    "  response_label = response.split()[0].strip(\"() \")  # Extract the answer label\n",
    "  target_label = target.strip(\"() \")\n",
    "  return response_label == target_label\n",
    "\n",
    "async def main(args):\n",
    "\n",
    "  dataset = datasets.load_dataset(\"lukaemon/bbh\", \"reasoning_about_colored_objects\")\n",
    "  subset = dataset[\"test\"].shuffle(seed=args.seed).select(range(args.limit))\n",
    "  # for item in subset:\n",
    "  #   print(item)\n",
    "  # example : {\"input\":xxxx,\"target\":(F)}\n",
    "\n",
    "  prompt_template = get_prompt_template() \n",
    "\n",
    "  semaphore = asyncio.Semaphore(args.concurrency)\n",
    "\n",
    "  from pprint import pprint\n",
    "  async def process_example(example):\n",
    "    async with semaphore:\n",
    "      input_ = example[\"input\"]\n",
    "      target = example[\"target\"]\n",
    "      response = await get_llm_response_async(input_, prompt_template, args.model)\n",
    "      is_correct = evaluate(response, target)\n",
    "      result = {\n",
    "        'question': input_,\n",
    "        'ground_truth': target,\n",
    "        'model_response': response,\n",
    "        'is_correct': is_correct\n",
    "      }\n",
    "      # if not is_correct:\n",
    "      #   print(result)\n",
    "      return result\n",
    "\n",
    "  tasks = [process_example(example) for example in subset] # result list\n",
    "\n",
    "  evaluation_results = await tqdm_asyncio.gather(*tasks, desc=\"Processing examples\")\n",
    " \n",
    "  # Calculate and print the metrics\n",
    "  accuracy = 0\n",
    "  # TODO: calculate accuracy\n",
    "  example_pass = sum(1 for res in evaluation_results if res[\"is_correct\"])\n",
    "  accuracy = example_pass / len(tasks) * 100\n",
    "  print(f\"Accuracy: {accuracy:.2f}\")\n",
    "  \n",
    "\n",
    "  # TODO: implement any other metric that you think might be usefull\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  args = argparse.ArgumentParser()\n",
    "  args.add_argument(\"--limit\", type=int, default=100) # limit 100 examples\n",
    "  args.add_argument(\"--model\", type=str, default=\"gpt-3.5-turbo\")\n",
    "  args.add_argument(\"--seed\", type=int, default=42)\n",
    "  args.add_argument(\"--concurrency\", type=int, default=5)\n",
    "  \n",
    "  args = args.parse_known_args()[0]\n",
    "  \n",
    "  asyncio.run(main(args))\n",
    "  "
   ],
   "id": "9d9c547d9084d4f0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "The following piece of code supports Alibaba model \"qwen\"\n",
    "\n",
    "prompts：\n",
    "1. 请根据描述的内容回答问题，给出正确选项的编号即可，不需要其他信息   86.00\n",
    "2. Answer the question:  94.00\n",
    "3. 请回答问题：   96.00\n",
    "4. 请根据给出的描述信息回答问题，选择最正确的选项，返回选项的编号：    84.00"
   ],
   "id": "d9bfaee06deb76d9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T05:29:31.076899Z",
     "start_time": "2024-11-04T05:26:32.887763Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "import os\n",
    "import openai\n",
    "import datasets\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "import argparse\n",
    "from tqdm.asyncio import tqdm_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "def get_prompt_template():\n",
    "  print(\"Enter a prompt:\")\n",
    "  user_input = input().strip()\n",
    "  if not user_input:\n",
    "    user_input = \"\"\"Answer the question: \"\"\"\n",
    "  print(user_input)\n",
    "  return user_input\n",
    "\n",
    "# get response from AI model\n",
    "async def get_llm_response_async(prompt, prompt_template, model):\n",
    "  formatted_prompt = prompt_template + prompt\n",
    "  alibaba_api_key = os.getenv(\"DASHSCOPE_API_KEY\")\n",
    "  #print(f\"ALIBABA API key:{alibaba_api_key}\")\n",
    "  client = openai.AsyncOpenAI(api_key=alibaba_api_key,\n",
    "                              base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\"\n",
    "                              )\n",
    "  \n",
    "  response = await client.chat.completions.create(\n",
    "      model=model,\n",
    "      messages=[\n",
    "          {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "          {\"role\": \"user\", \"content\": formatted_prompt}\n",
    "      ],\n",
    "      max_tokens=500,  # Adjust as needed\n",
    "      n=1, \n",
    "      stop=None,\n",
    "      temperature=0.0, #0-1\n",
    "  )\n",
    "\n",
    "  return response.choices[0].message.content.strip()\n",
    "import re\n",
    "def evaluate(response, target):\n",
    "  # response_label = response.split()[0].strip(\"() \")\n",
    "  # taget_label = taget.strip(\"() \")\n",
    "  \n",
    "  response_label = re.search(r'\\(([A-Z]{1})\\)',response)\n",
    "  if response_label:\n",
    "      response_label = response_label.group(0)\n",
    "      return target == response_label\n",
    "  \n",
    "  #print(f\"response_label:{response_label}; target_lebal:{target}\")\n",
    "\n",
    "  return False \n",
    "  \n",
    "\n",
    "async def main(args):\n",
    "\n",
    "  dataset = datasets.load_dataset(\"lukaemon/bbh\", \"reasoning_about_colored_objects\")\n",
    "  subset = dataset[\"test\"].shuffle(seed=args.seed).select(range(args.limit))\n",
    "  # for item in subset:\n",
    "  #   print(item)\n",
    "  # example : {\"input\":xxxx,\"target\":(F)}\n",
    "\n",
    "  prompt_template = get_prompt_template() # user_input or \"Answer the question:\"\n",
    "\n",
    "  semaphore = asyncio.Semaphore(args.concurrency)\n",
    "\n",
    "  from pprint import pprint\n",
    "  async def process_example(example):\n",
    "    async with semaphore:\n",
    "      input_ = example[\"input\"]\n",
    "      target = example[\"target\"]\n",
    "      response = await get_llm_response_async(input_, prompt_template, args.model)\n",
    "      is_correct = evaluate(response, target)\n",
    "      result = {\n",
    "        'question': input_,\n",
    "        'ground_truth': target,\n",
    "        'model_response': response,\n",
    "        'is_correct': is_correct\n",
    "      }\n",
    "      # if not is_correct:\n",
    "      #   print(result)\n",
    "      return result\n",
    "\n",
    "  tasks = [process_example(example) for example in subset] # result list\n",
    "\n",
    "  evaluation_results = await tqdm_asyncio.gather(*tasks, desc=\"Processing examples\")\n",
    " \n",
    "  # Calculate and print the metrics\n",
    "  accuracy = 0\n",
    "  # TODO: calculate accuracy\n",
    "  example_pass = sum(1 for res in evaluation_results if res[\"is_correct\"])\n",
    "  accuracy = example_pass / len(tasks) * 100\n",
    "  print(f\"Accuracy: {accuracy:.2f}\")\n",
    "  \n",
    "\n",
    "  # TODO: implement any other metric that you think might be usefull\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  args = argparse.ArgumentParser()\n",
    "  args.add_argument(\"--limit\", type=int, default=100) # limit 100 examples\n",
    "  args.add_argument(\"--model\", type=str, default=\"qwen-plus\")\n",
    "  args.add_argument(\"--seed\", type=int, default=42)\n",
    "  args.add_argument(\"--concurrency\", type=int, default=5)\n",
    "  \n",
    "  args = args.parse_known_args()[0]\n",
    "  \n",
    "  asyncio.run(main(args))"
   ],
   "id": "6285d253f63b9046",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a prompt:\n",
      "请回答问题：\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing examples: 100%|██████████| 100/100 [02:47<00:00,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "890e85b8d7f5a7f9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
